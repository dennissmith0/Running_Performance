{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vZJSy460KuCK"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "_L3DJhIVFFaw"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dennissmith0/Running_Performance/main/prep/training_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Display the first few rows of the dataframe\n",
        "# print(df.head())\n",
        "\n",
        "# # Get a summary of the dataframe\n",
        "# print(df.info())\n",
        "\n",
        "# # Generate descriptive statistics of the dataframe\n",
        "# print(df.describe())\n",
        "\n",
        "# # Check for missing values\n",
        "# print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "uAtFK2nTInT6"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the \"Activity Date\" column to datetime index\n",
        "df['Activity Date'] = pd.to_datetime(df['Activity Date'])\n",
        "df.set_index('Activity Date', inplace=True)"
      ],
      "metadata": {
        "id": "RBh1YAa3773V"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Activity ID', 'Activity Name', 'Media', 'Commute', 'From Upload', 'Filename', 'Athlete Weight',\n",
        "                 'Activity Gear', 'Number of Runs', 'Prefer Perceived Exertion',\n",
        "                 'Average Temperature', 'Elevation Loss', 'Average Speed'], inplace=True)"
      ],
      "metadata": {
        "id": "BuL4iAdvIxAZ"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_columns_with_prefix(df, prefix):\n",
        "    columns_to_remove = [column for column in df.columns if column.startswith(prefix)]\n",
        "    df.drop(columns=columns_to_remove, inplace=True)\n",
        "    return df\n",
        "\n",
        "df = remove_columns_with_prefix(df, '<span')\n"
      ],
      "metadata": {
        "id": "0ax93cq2HpR1"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some columns are repeats with more decimals, keep the rounded up decimals columns, remove the extras\n",
        "def drop_columns_with_extra_decimals(df, suffix):\n",
        "    columns_with_extra_decimals = [column for column in df.columns if column.endswith(suffix)]\n",
        "    df.drop(columns=columns_with_extra_decimals, inplace=True)\n",
        "    return df\n",
        "\n",
        "df = drop_columns_with_extra_decimals(df, '.1')"
      ],
      "metadata": {
        "id": "EtoWqhfq21pW"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run for dropping each column with empty columns\n",
        "def drop_columns_with_null(df):\n",
        "    columns_with_null = df.columns[df.isnull().sum() == len(df)]\n",
        "    df.drop(columns=columns_with_null, inplace=True)\n",
        "    return df\n",
        "\n",
        "df = drop_columns_with_null(df)"
      ],
      "metadata": {
        "id": "r3IM3XPvIdD8"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_columns_with_few_values(dataframe, threshold):\n",
        "    columns_to_remove = [column for column in dataframe.columns if dataframe[column].count() < threshold]\n",
        "    dataframe.drop(columns=columns_to_remove, inplace=True)\n",
        "    return dataframe\n",
        "\n",
        "# Remove columns with less than 1000 values\n",
        "df = remove_columns_with_few_values(df, 1000)"
      ],
      "metadata": {
        "id": "uaw8IEG94DDi"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To adjust the \"Activity Type\" column to eliminate activities with less than 10% of the max value and convert it into\n",
        "# separate indicator columns for each activity, you can use the following function:\n",
        "def adjust_and_convert_activity_type_column(df):\n",
        "    activity_counts = df['Activity Type'].value_counts()\n",
        "    max_value = activity_counts.max()\n",
        "    threshold = max_value * 0.1\n",
        "\n",
        "    filtered_activities = activity_counts[activity_counts >= threshold].index.tolist()\n",
        "\n",
        "    # If the activity does not make the threshold, remove the activity (we are considering these activities as \"outliers\", with little effect on training)\n",
        "    df.loc[~df['Activity Type'].isin(filtered_activities), 'Activity Type'] = None\n",
        "    df.dropna(subset=['Activity Type'], inplace=True)\n",
        "\n",
        "\n",
        "    for activity in filtered_activities:\n",
        "        df[activity] = df['Activity Type'].apply(lambda x: 1 if x == activity else 0)\n",
        "\n",
        "    df.drop(columns=['Activity Type'], inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Adjust and convert the \"Activity Type\" column. This will allow the model to capture the influence of different activities on running performance.\n",
        "df = adjust_and_convert_activity_type_column(df)"
      ],
      "metadata": {
        "id": "HqAJhxIc9wQ0"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To impute missing values in the \"Average Heart Rate\" column with a random value within a range around the average, you can use the following function:\n",
        "def impute_average_heart_rate(df):\n",
        "    average_hr = df['Average Heart Rate'].mean()\n",
        "\n",
        "    # Generate random values within the range of average_hr Â± 10\n",
        "    random_values = np.random.uniform(average_hr - 10, average_hr + 10, size=df['Average Heart Rate'].isnull().sum())\n",
        "\n",
        "    # Replace missing values with the generated random values\n",
        "    df.loc[df['Average Heart Rate'].isnull(), 'Average Heart Rate'] = random_values\n",
        "\n",
        "    return df\n",
        "\n",
        "# Impute missing values in \"Average Heart Rate\" column\n",
        "df = impute_average_heart_rate(df)"
      ],
      "metadata": {
        "id": "tRfzvSSAqsPq"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering: Training Stress\n",
        "# For simplicity, let's define training stress as distance * average heart rate\n",
        "\n",
        "# Convert 'Distance' and 'Average Heart Rate' columns to numeric types\n",
        "df['Distance'] = pd.to_numeric(df['Distance'], errors='coerce')\n",
        "df['Average Heart Rate'] = pd.to_numeric(df['Average Heart Rate'], errors='coerce')\n",
        "\n",
        "Training_Stress_Space = df['Distance'] * df['Average Heart Rate']\n",
        "Training_Stress_Time = (df['Elapsed Time'] / 60) * df['Average Heart Rate']\n",
        "#df['Training Stress'] = Training_Stress_Time / Training_Stress_Space\n",
        "# Check if distance is zero, assign Training Stress Time value if true, else calculate Training Stress\n",
        "df['Training Stress'] = np.where(df['Distance'] == 0, Training_Stress_Time, Training_Stress_Time / Training_Stress_Space) # but now its a ridiciluously high score...\n",
        "\n",
        "# But note rows that are workouts, e.g, not a run, the stress is much higher. Is this true?"
      ],
      "metadata": {
        "id": "N3Se4P8Odp0d"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FEATURE:\n",
        "# if add measure of days between activites, do so before removing activities that are below threshold percentage of max activity\n",
        "\n",
        "# for imputing average heart rate value: TO DO: look at the activity type first, then get the average of those types."
      ],
      "metadata": {
        "id": "TrmfsCt-pn_D"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Max Heart Rate'].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow5yXDpcsmXN",
        "outputId": "67bff462-814b-4918-8fb3-7dbcb677f556"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "462"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Relative Effort'].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA1NpfyHssrh",
        "outputId": "68f4e56b-88e7-472d-ce21-43d62a37d64d"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "462"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "XL93rLt8BR-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924693b2-bef6-4af3-b99c-d48e7da8e6f7"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Elapsed Time', 'Distance', 'Max Heart Rate', 'Relative Effort',\n",
              "       'Moving Time', 'Max Speed', 'Elevation Gain', 'Elevation Low',\n",
              "       'Elevation High', 'Max Grade', 'Average Grade', 'Max Cadence',\n",
              "       'Average Cadence', 'Average Heart Rate', 'Calories', 'Run', 'Ride',\n",
              "       'Hike', 'Yoga', 'Rock Climb', 'Walk', 'Training Stress'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For now, in lieu of adding conditions that adjust the training stress score for activities such as yoga and rock climbing, lets remove these activities/rows with really high values.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "70J0H7zew4AS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code filters the dataframe to keep only the rows where the 'Training Stress' value is less than or equal to 500. The resulting filtered dataframe is assigned back to the variable df, effectively removing the rows with high 'Training Stress' scores.\n",
        "df = df[df['Training Stress'] <= 500]\n"
      ],
      "metadata": {
        "id": "OdGRQUhdwqQT"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can use the following function to check the entire dataframe for NaN values and impute the average value of each column:\n",
        "def impute_nan_with_average(df):\n",
        "    for column in df.columns:\n",
        "        if df[column].isnull().any():\n",
        "            average = df[column].mean()\n",
        "            df[column].fillna(average, inplace=True)\n",
        "    return df\n",
        "\n",
        "# Impute NaN values with the average value of each column\n",
        "df = impute_nan_with_average(df)"
      ],
      "metadata": {
        "id": "yk_w6oRyx1eX"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Baseline Model\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fuZBQvJaxSpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "bsPGAL3kxalE"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features X and target y\n",
        "# Here we're assuming that 'performance' is your target variable\n",
        "X = df.drop('Training Stress', axis=1)\n",
        "y = df['Training Stress']"
      ],
      "metadata": {
        "id": "7NFhFwHrxbd4"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "l8R44MWjxnXE"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a baseline model using Linear Regression\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "lr.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "m1E9A8tYxihv",
        "outputId": "03b566ad-a614-4dee-f776-67e733ef3fc7"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = lr.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "RufNkOvdxj74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqGCmIDwxk0i",
        "outputId": "17308438-7efb-4e8d-e5a6-2cd06826aaa6"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 55.43209281548262\n"
          ]
        }
      ]
    }
  ]
}