# -*- coding: utf-8 -*-
"""baseline_performance_score.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JXUw0gitid-zLeKPt8lELgFIN6We7rcg
"""

# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Load the data
df = pd.read_csv('https://raw.githubusercontent.com/dennissmith0/Running_Performance/main/prep/training_data.csv')

# # Display the first few rows of the dataframe
# print(df.head())

# # Get a summary of the dataframe
# print(df.info())

# # Generate descriptive statistics of the dataframe
# print(df.describe())

# # Check for missing values
# print(df.isnull().sum())

# Convert the "Activity Date" column to datetime
df['Activity Date'] = pd.to_datetime(df['Activity Date'])

# Sort data by date just to be sure
df = df.sort_values('Activity Date')

# Calculate days between activities and create new column that serves as measure for 'Rest Days'.
# NOTE: this measure reflects ALL activities prior to the next function which removes all activities that are not a 'Run'
df['Days Between Activity'] = df['Activity Date'].diff().dt.days

# First value = NaN, replace with 0.
if pd.isna(df.loc[0, 'Days Between Activity']):
    df.loc[0, 'Days Between Activity'] = 0.0


# Now set as datetime index
df.set_index('Activity Date', inplace=True)

# For now, remove all activities that are not a Run
df = df[df['Activity Type'].isin(['Run'])] #.reset_index(drop=True)
# Drop the column
df.drop(columns=['Activity Type'], inplace=True)

# Replace NaN values in the 'Average Speed' column with the calculated speed using the 'Distance.1' and 'Moving Time' columns
def replace_nan_average_speed(df):
    df['Average Speed'] = df.apply(lambda row: row['Distance.1'] / row['Moving Time'] if pd.isna(row['Average Speed']) else row['Average Speed'], axis=1)
    return df

# Replace NaN values in 'Average Speed' column
df = replace_nan_average_speed(df)

df.drop(columns=['Elapsed Time', 'Activity ID', 'Activity Name', 'Media', 'Commute', 'From Upload', 'Filename', 'Athlete Weight',
                 'Activity Gear', 'Number of Runs', 'Prefer Perceived Exertion',
                 'Average Temperature', 'Elevation Loss', 'Gear'], inplace=True)

# Drop potentially important features with high NaN columns for now, that we intend to find a measure that fills the value in a meaningful way.
df.drop(columns=['Grade Adjusted Distance'], inplace=True)

def remove_columns_with_prefix(df, prefix):
    columns_to_remove = [column for column in df.columns if column.startswith(prefix)]
    df.drop(columns=columns_to_remove, inplace=True)
    return df

df = remove_columns_with_prefix(df, '<span')

# Some columns are repeats with more decimals, keep the rounded up decimals columns, remove the extras
def drop_columns_with_extra_decimals(df, suffix):
    columns_with_extra_decimals = [column for column in df.columns if column.endswith(suffix)]
    df.drop(columns=columns_with_extra_decimals, inplace=True)
    return df

df = drop_columns_with_extra_decimals(df, '.1')

# Run for dropping each column with empty columns or 50% NaN values
def drop_columns_with_null(df):
    columns_with_null = df.columns[df.isnull().sum() >= (.50 * len(df))]
    df.drop(columns=columns_with_null, inplace=True)
    return df

df = drop_columns_with_null(df)

def remove_columns_with_few_values(dataframe, threshold):
    columns_to_remove = [column for column in dataframe.columns if dataframe[column].count() < threshold]
    dataframe.drop(columns=columns_to_remove, inplace=True)
    return dataframe

# Remove columns with less than 1000 values
# df = remove_columns_with_few_values(df, 1000)
df = remove_columns_with_few_values(df, 50)

df.isnull().sum()

df[df['Average Heart Rate'].isna()].tail(20)

df.tail(10)

# SAVE FOR LATER MODEL. This model will only be modeled on "Run"

# # To adjust the "Activity Type" column to eliminate activities with less than 10% of the max value and convert it into
# # separate indicator columns for each activity, you can use the following function:
# def adjust_and_convert_activity_type_column(df):
#     activity_counts = df['Activity Type'].value_counts()
#     max_value = activity_counts.max()
#     threshold = max_value * 0.1

#     filtered_activities = activity_counts[activity_counts >= threshold].index.tolist()

#     # If the activity does not make the threshold, remove the activity (we are considering these activities as "outliers", with little effect on training)
#     df.loc[~df['Activity Type'].isin(filtered_activities), 'Activity Type'] = None
#     df.dropna(subset=['Activity Type'], inplace=True)


#     for activity in filtered_activities:
#         df[activity] = df['Activity Type'].apply(lambda x: 1 if x == activity else 0)

#     df.drop(columns=['Activity Type'], inplace=True)

#     return df

# # Adjust and convert the "Activity Type" column. This will allow the model to capture the influence of different activities on running performance.
# df = adjust_and_convert_activity_type_column(df)

# To impute missing values in the "Average Heart Rate" column with a random value within a range around the average, you can use the following function:
def impute_average_heart_rate(df):
    average_hr = df['Average Heart Rate'].mean()

    # Generate random values within the range of average_hr Â± 10
    random_values = np.random.uniform(average_hr - 10, average_hr + 10, size=df['Average Heart Rate'].isnull().sum())

    # Replace missing values with the generated random values
    df.loc[df['Average Heart Rate'].isnull(), 'Average Heart Rate'] = random_values

    return df

# Impute missing values in "Average Heart Rate" column
df = impute_average_heart_rate(df)

# Feature Engineering: Training Stress
# For simplicity, let's define training stress as distance * average heart rate

# Convert 'Distance' and 'Average Heart Rate' columns to numeric types
df['Distance'] = pd.to_numeric(df['Distance'], errors='coerce')
df['Average Heart Rate'] = pd.to_numeric(df['Average Heart Rate'], errors='coerce')

Training_Stress_Space = df['Distance'] * df['Average Heart Rate']
Training_Stress_Time = (df['Moving Time'] / 60) * df['Average Heart Rate']
#df['Training Stress'] = Training_Stress_Time / Training_Stress_Space
# Check if distance is zero, assign Training Stress Time value if true, else calculate Training Stress
df['Training Stress'] = np.where(df['Distance'] == 0, Training_Stress_Time, Training_Stress_Time / Training_Stress_Space) # but now its a ridiciluously high score...

# But note rows that are workouts, e.g, not a run, the stress is much higher. Is this true?

# FEATURE:
# if add measure of days between activites, do so before removing activities that are below threshold percentage of max activity

# for imputing average heart rate value: TO DO: look at the activity type first, then get the average of those types.

df['Max Heart Rate'].isnull().sum()

df['Relative Effort'].isnull().sum()

df.columns

# # Removing for now, given that it leads to 'ValueError: Input X contains infinity or a value too large for dtype('float64').' when making predictions
# # Do we need? Given that 'Average Speed' = meters/second

# def calculate_average_pace(df):
#     # Convert moving time to minutes
#     moving_time_minutes = df['Moving Time'] / 60

#     # Convert distance from kilometers to miles
#     distance_miles = df['Distance'] * 0.621371

#     # # Reset the index of the dataframe
#     # df.reset_index(drop=True, inplace=True)
#     # # # Calculate average pace in minutes per mile
#     # # if df['Run'] == 1:
#     # #   df['Average Pace (min/mile)'] = moving_time_minutes / distance_miles
#     #     # Calculate average pace in minutes per mile only for 'run' activities
#     # df.loc[df['Run'] == 1, 'Average Pace (min/mile)'] = moving_time_minutes / distance_miles
#     # Calculate average pace in minutes per mile
#     df['Average Pace (min/mile)'] = moving_time_minutes / distance_miles


#     return df

# # Calculate the average pace
# df = calculate_average_pace(df)

df.tail(10)

"""For now, in lieu of adding conditions that adjust the training stress score for activities such as yoga and rock climbing, lets remove these activities/rows with really high values.

---


"""

# # Don't need in Version 1.0 of model as we only have 'Run' activity type
# df['Training Stress'].max()
# # This code filters the dataframe to keep only the rows where the 'Training Stress' value is less than or equal to 500. The resulting filtered dataframe is assigned back to the variable df, effectively removing the rows with high 'Training Stress' scores.
# df = df[df['Training Stress'] <= 500]

"""#TO-DO:
Make this function generate random values within a window of the average, rather than a constant average value for all NaN.

For fine-tuning: look at other features, and find similar values in other rows, and then impute comparable values for comparable runs.
"""

# You can use the following function to check the entire dataframe for NaN values and impute the average value of each column:
def impute_nan_with_average(df):
    for column in df.columns:
        if df[column].isnull().any():
            average = df[column].mean()
            df[column].fillna(average, inplace=True)
    return df

# Impute NaN values with the average value of each column
df = impute_nan_with_average(df)

df.isnull().sum()

"""# New Section

---


"""

# FEATURE ENGINEERING: Training Session Intensity

# Firstly, it's advisable to normalize these features so that they are on a similar scale. This can be done using Min-Max normalization which scales the features to be between 0 and 1.
features_to_normalize = ['Distance', 'Relative Effort', 'Elevation Gain', 'Moving Time']

for feature in features_to_normalize:
    df[feature + "_norm"] = (df[feature] - df[feature].min()) / (df[feature].max() - df[feature].min())

# Create the 'Training Session Intensity' as a weighted sum of these features
# Here we are giving equal weight (0.25) to each of the four features, but you could adjust these weights based on what you think contributes more to the intensity of a training session.
# For example, if you think 'Relative Effort' is a more important factor, you might give it a higher weight.
df['Training Session Intensity'] = (df['Distance_norm'] * 0.25
                                    + df['Relative Effort_norm'] * 0.25
                                    + df['Elevation Gain_norm'] * 0.25
                                    + df['Moving Time_norm'] * 0.25)

# Drop the normalized columns, as they were just intermediates for this calculation:
df.drop([feature + "_norm" for feature in features_to_normalize], axis=1, inplace=True)

"""***Cumulative Load: ***
This is a measure of the total stress placed on your body over time, which we can calculate as a rolling sum of training session intensity over a certain window of time.
"""

# FEATURE ENGINEERING: Cumulative Load
  # Dependent on Training Session Intensity

# "Cumulative Load" is a rolling sum of the training session intensity over a certain period of time.
# To calculate this, you can use the pandas rolling function, which provides rolling window calculations.

# Set the window size for cumulative load calculation
window_size = 7 # for example, to represent a week

# Calculate Cumulative Load
df['Cumulative Load'] = df['Training Session Intensity'].rolling(window=window_size).sum()

# Replace the NaN values for the first 6 rows
for i in range(6):
    df.loc[df.index[i], 'Cumulative Load'] = df.loc[df.index[:i+1], 'Training Session Intensity'].sum()

df[df['Training Stress'] == df['Training Stress'].max()]

df[df['Training Session Intensity'] == df['Training Session Intensity'].max()]

df[df['Cumulative Load'] == df['Cumulative Load'].max()]

df[df['Distance'] == df['Distance'].max()]

# FEATURE ENGINEERING: Performance/Readiness Score

# Engineer a performance metric that is a function of:
# Recent training load (e.g., the 'Cumulative Load' we just created)
# Rest days ('Days Between Activity')
# Intensity of the workouts ('Training Session Intensity')
# Other physiological metrics available in your data (like heart rate, speed, etc.)

# Define weights for each factor
weight_cumulative_load = 0.4
weight_rest_days = 0.2
weight_intensity = 0.4

# Calculate performance score
df['Performance Score'] = (weight_cumulative_load * df['Cumulative Load'] +
                           weight_rest_days * df['Days Between Activity'] +
                           weight_intensity * df['Training Session Intensity'])

df[df['Performance Score'] == df['Performance Score'].max()]

"""

---

# **Baseline Model**



---

"""

# Import necessary libraries
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Split the data into features X and target y
# Here we're assuming that 'Training Stress' is the target variable
X = df.drop('Performance Score', axis=1)
y = df['Performance Score']

# Calculate the mean value of the target variable and use it as a constant prediction for every data point.
# This baseline model assumes that all predictions will be equal to the mean value, disregarding any input features.
y.mean()

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a baseline model using Linear Regression
lr = LinearRegression()

# Fit the model to the training data
lr.fit(X_train, y_train)

# Make predictions on the test data
y_pred = lr.predict(X_test)
y_pred

"""The coefficient of determination (R-squared) is a statistical measure that indicates the proportion of the variance in the dependent variable (target variable) that can be explained by the independent variables in the regression model. It ranges between 0 and 1, where:

*   R-squared = 1 indicates that the model perfectly predicts the target variable.

*   R-squared = 0 indicates that the model fails to explain any of the variability in the target variable.

An R-squared value closer to 1 suggests that the independent variables in your model explain a larger portion of the variability in the target variable. It indicates a better fit of the model to the data.

However, it's important to note that R-squared alone does not provide information about the correctness of the model or the significance of the independent variables. It doesn't consider the possibility of overfitting or the presence of omitted variables. Therefore, it's crucial to interpret R-squared in conjunction with other evaluation metrics, domain knowledge, and the specific context of your problem.
"""

r_squared = lr.score(X, y)
r_squared

"""Mean Squared Error (MSE), it is a common evaluation metric for regression problems, including linear regression. It measures the average of the squares of the errorsâthat is, the average squared difference between the estimated values and the actual value. The MSE is a measure of the quality of an estimatorâit is always non-negative, and values closer to zero are better.

A key property of the MSE is that it penalizes larger errors more than smaller ones, due to the squared term. This makes it a useful metric when large errors are particularly undesirable.
"""

# Evaluate the model
def calculate_mse(actual, predicted):
  mse = mean_squared_error(actual, predicted)
  return mse

mse = calculate_mse(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

"""Root Mean Squared Error (RMSE): This is the square root of the MSE. The RMSE is in the same units as the dependent variable, making it more interpretable than the MSE. It also penalizes large errors more than the MAE."""

def calculate_rmse(actual, predicted):
    mse = mean_squared_error(actual, predicted)
    rmse = np.sqrt(mse)
    return rmse

# Calculate RMSE
rmse = calculate_rmse(y_test, y_pred)
print(f'RMSE: {rmse}')